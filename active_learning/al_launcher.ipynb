{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from active_learning.al import AL\n",
    "from utils.utils import get_tasks\n",
    "\n",
    "# exp selection\n",
    "exp_name = 'DFFC_8D_4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load al instance from database\n",
    "al = AL(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the current al instance to the database\n",
    "al.save_exp_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## AL main workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### recipe generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# generate next trial using Bayesian Optimization, specify beta if needed, e.g. beta=100 for exploration, beta=0.2 for default\n",
    "al.generate_botorch_trial(n=36, aquisition = 'qUCB', optimizer_kwargs = {'options':{'maxiter':20000000}, 'sequential':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate next trial using SOBOL method (random select)\n",
    "al.generate_sobol_trial(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update the recipe table on the database, if trial index is not specified, the recipe of the latest trial will be uploaded\n",
    "al.update_recipe_table(trial_index=None, add_pred=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### sample preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# benchmark specification\n",
    "benchmark = None\n",
    "# benchmark={5: '1_0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# command opentrons to prepare the sample for the latest trial, following the ot2_run_configs of the exp\n",
    "al.make_sample(trial_index=None, benchmark=benchmark, operator_name='chu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update the sample table on the database, if trial index is not specified, the sample of the latest trial will be uploaded. Note that sample table calculation is based on local ot2_run_configs.py under project folder, not the one on ot2 server.\n",
    "al.update_sample_table(trial_index=None, benchmark=benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### sample testing complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell after sample testing and data analysis is completed, then go back to the BO step\n",
    "al.mark_trial_complete(trial_index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## AL monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update the exp with the latest result\n",
    "al.update_exp_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exp monitor for windows\n",
    "al.exp_monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exp monitor for mac and linux\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(al.exp_monitor().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check abandon reason\n",
    "al.exp.trials[0].abandoned_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## AL manual edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update the exp with the latest result and force match previous trials with the results in the database\n",
    "al.update_exp_result(force_update_trial=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually add a trial\n",
    "trial_df = get_tasks(exp_name, task_name='manual')\n",
    "al.add_manual_trial(trial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# abandon an certain arm in a trial\n",
    "al.abandon_arm(0, '0_18', 'abandoned in manual test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# abandon a whole trial\n",
    "al.abandon_trial(9, 'test trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ax.modelbridge.cross_validation import cross_validate\n",
    "from ax.plot.contour import interact_contour\n",
    "from ax.plot.diagnostic import interact_cross_validation\n",
    "from ax.plot.scatter import interact_fitted\n",
    "from ax.plot.slice import interact_slice\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = al.get_bo_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contour plots\n",
    "render(interact_contour(model=model, metric_name='max_power'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross-validation plots\n",
    "cv_results = cross_validate(model)\n",
    "print('current r_squared is: ', al.calculate_r_squared(cv_results))\n",
    "render(interact_cross_validation(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Slice plots\n",
    "render(interact_slice(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tile plots\n",
    "render(interact_fitted(model, rel=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Danger Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete the current active learning process from the database\n",
    "al.delete_exp_on_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only use this if you want to start a new experiment, note that the previous experiment has to be manually deleted, first, because the script refuses to overwrite the previous experiment by default\n",
    "al = AL(exp_name, load_from_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
